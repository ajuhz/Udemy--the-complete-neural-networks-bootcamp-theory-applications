{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Pytorch CNN MNIST digit recognition.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajuhz/Udemy-neural-network-boorcamp/blob/main/Pytorch%20CNN%20MNIST%20digit%20recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGACf7YuZckO"
      },
      "source": [
        "# Pytorch : CNN MNIST digit recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyQmlesdZck1"
      },
      "source": [
        "# Consider one architecture for CNN\n",
        "# take motivation from SOA architectures\n",
        "# we are going to use below architecture for MNIST problem\n",
        "# Later we are also going to play around changing the architecture to see the performance\n",
        "# input image size for MNIST dataset is 28x28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcME1OPxZck5"
      },
      "source": [
        "![cnn mnist](https://user-images.githubusercontent.com/30661597/61713471-3c957d00-ad8b-11e9-9a38-e3f4d1e72565.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHy9wLAHZck7"
      },
      "source": [
        "#import required packages \n",
        "#impirt torch for using tensor and other basic pytorch utilities\n",
        "import torch\n",
        "# import torchvision package for the MNIST dataset and dataloader utility\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "#import torch.nn module for building NN architecture\n",
        "import torch.nn as nn\n",
        "# import transform for normalizing data, without this the process with end with error below\n",
        "# batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-zo27eKZck9"
      },
      "source": [
        "#creating dataset and dataloaders\n",
        "# first we will check without normalization then apply normalization\n",
        "# change the root path as per need based on running location for \n",
        "# colab it would be ./data if the data is there\n",
        "train_dataset = datasets.MNIST(root = './data',\n",
        "                               train = True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                              download = True)\n",
        "test_dataset = datasets.MNIST(root = './data',\n",
        "                               train = False,\n",
        "                              transform=transforms.ToTensor(),\n",
        "                              download = True)\n",
        "train_dataloader = DataLoader(dataset=train_dataset,batch_size=100,shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset,batch_size=100,shuffle=False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u38pWMhZck_",
        "outputId": "d18f0d82-63ab-42ed-f15e-28457450ebc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#check the length of the train dataloader\n",
        "print('Train Dataloader : ')\n",
        "print('No of batches:{}'.format(len(train_dataloader)))\n",
        "print('batch size:{}'.format(train_dataloader.batch_size))\n",
        "print('shape of data:{}'.format(train_dataloader.dataset.data.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Dataloader : \n",
            "No of batches:600\n",
            "batch size:100\n",
            "shape of data:torch.Size([60000, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2H1S2c2ZclE"
      },
      "source": [
        "# Creating the CNN architecture\n",
        "# Ref\n",
        "'''\n",
        "torch.nn.Conv2d(in_channels, \n",
        "                 out_channels, \n",
        "                 kernel_size, \n",
        "                 stride=1, \n",
        "                 padding=0, \n",
        "                 dilation=1, \n",
        "                 groups=1, \n",
        "                 bias=True, \n",
        "                 padding_mode='zeros')\n",
        "Here we are considering zero padding.\n",
        "Hence, to achive same size of the feature map as input we need to calculte the stride size.\n",
        "We will use maxpooling to reduce the feature size\n",
        "for conv1 \n",
        "(28-3 + 2*padd)/1 + 1 = 28 ==> padd = 1\n",
        "for maxpool we want the feature size to reduce to half so we need to use 2x2 size\n",
        "for conv1 \n",
        "(14-3 + 2*padd)/1 + 1 = 14 ==> padd = 1              \n",
        "'''\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=8,kernel_size=3,stride=1,padding=1)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(num_features=8)\n",
        "        self.relu = nn.ReLU()\n",
        "        #will check if we change the kernel size how it affects\n",
        "        self.conv2 = nn.Conv2d(in_channels=8,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(num_features=32)\n",
        "        self.fc1 = nn.Linear(in_features=32*7*7,out_features=600)\n",
        "        self.fc2 = nn.Linear(in_features=600,out_features=10)\n",
        "        #self.droput = nn.Dropout(p=0.5)\n",
        "    def forward(self,X):\n",
        "        output = self.conv1(X)\n",
        "        output = self.batchnorm1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.maxpool(output)\n",
        "        output = self.conv2(output)\n",
        "        output = self.batchnorm2(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.maxpool(output)\n",
        "        output = output.view(-1,1568)\n",
        "        output = self.fc1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.fc2(output)\n",
        "        return output      "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMLax3nvZclI"
      },
      "source": [
        "model = CNN()\n",
        "CUDA = torch.cuda.is_available()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(),lr=0.01)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkNSmnENZclJ",
        "outputId": "d4e646db-8cbb-4f4d-f96a-52cf0f12bf35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#training the model\n",
        "epochs = 10\n",
        "if CUDA:\n",
        "    model = model.cuda()\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    iter_loss=0\n",
        "    sample=0\n",
        "    correct=0\n",
        "    \n",
        "    for i,(X,y) in enumerate(train_dataloader):\n",
        "        if CUDA:\n",
        "            X = X.cuda()\n",
        "            y = y.cuda()\n",
        "        output = model(X)\n",
        "        loss = criterion(output,y) # we need to give output in raw format then y else will throw error\n",
        "        iter_loss += loss.item()\n",
        "        sample += y.shape[0]\n",
        "        _,predicted = torch.max(output,axis = 1)\n",
        "        correct += (predicted==y).sum()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('for epoch:{}, loss:{:.7f}, accuracy:{:.2f}%'.format(epoch,float(iter_loss/sample),float(100*correct/sample)))\n",
        "        \n",
        "        "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for epoch:0, loss:0.0037677, accuracy:92.51%\n",
            "for epoch:1, loss:0.0006443, accuracy:98.02%\n",
            "for epoch:2, loss:0.0005017, accuracy:98.48%\n",
            "for epoch:3, loss:0.0004087, accuracy:98.72%\n",
            "for epoch:4, loss:0.0003595, accuracy:98.90%\n",
            "for epoch:5, loss:0.0003078, accuracy:99.06%\n",
            "for epoch:6, loss:0.0002898, accuracy:99.08%\n",
            "for epoch:7, loss:0.0002743, accuracy:99.12%\n",
            "for epoch:8, loss:0.0002567, accuracy:99.21%\n",
            "for epoch:9, loss:0.0002233, accuracy:99.28%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzaqjROgZclO",
        "outputId": "68286c2a-029c-46aa-c51e-9166dc3e7c7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if CUDA:\n",
        "    model = model.cuda()\n",
        "model.eval()\n",
        "sample =0\n",
        "iter_loss =0\n",
        "correct =0\n",
        "for i,(X,y) in enumerate(test_dataloader):\n",
        "  if CUDA:\n",
        "    X = X.cuda()\n",
        "    y = y.cuda()\n",
        "  output = model(X)\n",
        "  loss = criterion(output,y) # we need to give output in raw format then y else will throw error\n",
        "  iter_loss += loss.item()\n",
        "  sample += y.shape[0]\n",
        "  _,predicted = torch.max(output,axis = 1)\n",
        "  correct += (predicted==y).sum()\n",
        "  #optimizer.zero_grad()\n",
        "  #loss.backward()\n",
        "  #optimizer.step()\n",
        "print('for test dataset loss:{:.7f}, accuracy:{:.6f}%'.format(epoch,float(iter_loss/sample),float(100*correct/sample)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for test dataset loss:9.0000000, accuracy:0.000382%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjXXhfMeZclT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
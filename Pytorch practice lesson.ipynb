{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pytorch library \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "#check pytorch version installed\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "#create one 1-D tensor and print the shape and data\n",
    "t1 = torch.tensor([1,2,3])\n",
    "print(t.shape)\n",
    "print(type(t))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "#create 2-D tensor and print the shape and elements\n",
    "t2 = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(t2.shape)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "#use of attribute shape and method size() for tensor\n",
    "#o/p is the same\n",
    "print(t2.shape)\n",
    "print(t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows of the tensor t2 -->\n",
      "using method size :3\n",
      "using attribute shape:3\n",
      "Heights of the tensor t2 -->\n",
      "using method size :3\n",
      "using attribute shape:3\n"
     ]
    }
   ],
   "source": [
    "#printing rows and heights of the tensor\n",
    "# print rows of the tensor t2\n",
    "print('Rows of the tensor t2 -->')\n",
    "print('using method size :{}'.format(str(t2.size(0))))\n",
    "print('using attribute shape:{}'.format(str(t2.shape[0])))\n",
    "#print heights of the tensor t2\n",
    "print('Heights of the tensor t2 -->')\n",
    "print('using method size :{}'.format(str(t2.size(1))))\n",
    "print('using attribute shape:{}'.format(str(t2.shape[1])))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "torch.FloatTensor\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "#create a float tensor\n",
    "t3_float = torch.FloatTensor([[1,2,3.],[4.,5.,6.]])\n",
    "print(t3_float)\n",
    "print(t3_float.type())\n",
    "#alternate approach \n",
    "t3_float = torch.tensor([[1.,2,3],[4.,5.,6.]],dtype=torch.float)\n",
    "print(t3_float)\n",
    "print(t3_float.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float64)\n",
      "torch.DoubleTensor\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float64)\n",
      "torch.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "#create a double tensor\n",
    "t4_double = torch.DoubleTensor([[1,2,3.],[4.,5.,6.]])\n",
    "print(t4_double)\n",
    "print(t4_double.type())\n",
    "#alternate aproach\n",
    "t4_double = torch.tensor([[1,2,3.],[4.,5.,6.]],dtype=torch.double)\n",
    "print(t4_double)\n",
    "print(t4_double.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5000)\n",
      "tensor(1.8708)\n",
      "tensor(3.5000, dtype=torch.float64)\n",
      "tensor(1.8708, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#calculating mean and standard deviation\n",
    "#calculate mean and standard devoation for t3_float and t4_double\n",
    "print(t3_float.mean())\n",
    "print(t3_float.std())\n",
    "print(t4_double.mean())\n",
    "print(t4_double.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "tensor([[[ 2.1491, -1.9523,  0.5236, -1.2723],\n",
      "         [ 0.2671,  0.4847,  0.3938,  1.7444],\n",
      "         [ 0.0934, -0.4298,  0.3893,  1.2825]],\n",
      "\n",
      "        [[-0.0108, -0.6404,  1.2542,  1.4042],\n",
      "         [ 0.3296, -0.2647, -0.3599, -0.6999],\n",
      "         [-0.4397,  0.0705, -0.2064,  0.5473]]])\n"
     ]
    }
   ],
   "source": [
    "#create 3-D tensor with random values\n",
    "t5_3d = torch.randn(2,3,4) # creates metrix of shape 2x3x5 with random numbers having normal distribution\n",
    "print(t5_3d.shape)\n",
    "print(t5_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "torch.Size([1, 9])\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.]])\n",
      "torch.Size([6, 1])\n",
      "tensor([[ 2.1491, -1.9523],\n",
      "        [ 0.5236, -1.2723],\n",
      "        [ 0.2671,  0.4847],\n",
      "        [ 0.3938,  1.7444],\n",
      "        [ 0.0934, -0.4298],\n",
      "        [ 0.3893,  1.2825],\n",
      "        [-0.0108, -0.6404],\n",
      "        [ 1.2542,  1.4042],\n",
      "        [ 0.3296, -0.2647],\n",
      "        [-0.3599, -0.6999],\n",
      "        [-0.4397,  0.0705],\n",
      "        [-0.2064,  0.5473]])\n",
      "torch.Size([12, 2])\n"
     ]
    }
   ],
   "source": [
    "#reshaping tensor\n",
    "# use of function view\n",
    "# reshape t2 into a row matrix\n",
    "print(t2.view(1,-1)) # -1 signifies that python will infer the #of rows / cols needed by itself\n",
    "print(t2.view(1,-1).shape)\n",
    "# reshape t3_float into a vector\n",
    "print(t3_float.view(-1,1))\n",
    "print(t3_float.view(-1,1).shape)\n",
    "#reshape t5_3d into 2-D shape\n",
    "print(t5_3d.view(12,2))\n",
    "print(t5_3d.view(12,2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6977, 0.9189, 0.9212, 0.9189, 0.4975],\n",
      "         [0.6369, 0.7879, 0.9593, 0.2589, 0.3649]],\n",
      "\n",
      "        [[0.1045, 0.8491, 0.7558, 0.4627, 0.5983],\n",
      "         [0.6461, 0.3436, 0.3833, 0.6924, 0.8397]],\n",
      "\n",
      "        [[0.7327, 0.2495, 0.4954, 0.4571, 0.7793],\n",
      "         [0.4767, 0.7323, 0.6802, 0.0586, 0.8420]]])\n",
      "tensor(0.6047)\n",
      "tensor([[[-0.0301,  0.5667,  0.0464,  1.1148,  0.6050],\n",
      "         [-0.3737, -0.0636, -0.0814, -0.0048,  0.4472]],\n",
      "\n",
      "        [[-0.7092, -1.4097, -0.1170, -1.0438,  0.3210],\n",
      "         [ 1.4698, -1.0193, -1.2248, -0.6520, -0.8735]],\n",
      "\n",
      "        [[-1.0096, -0.4447, -0.2860, -1.2361, -0.2690],\n",
      "         [ 1.0126, -2.0976, -0.3946,  0.6222, -0.4926]]])\n",
      "tensor(-0.2542)\n",
      "tensor(0.8102)\n"
     ]
    }
   ],
   "source": [
    "#rand and randn functions\n",
    "# rand is used to create matrix of random numbers\n",
    "#randn is used to create matrix of random numbers with normal distribution , mnean 0\n",
    "t6_rand = torch.rand(3,2,5)\n",
    "print(t6_rand)\n",
    "print(t6_rand.mean())\n",
    "t7_randn = torch.randn(3,2,5)\n",
    "print(t7_randn)\n",
    "print(t7_randn.mean()) # mean nearly 0 and std nearly 1\n",
    "print(t7_randn.std())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 9, 7, 8, 6])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "#Create an array of 5 random integers from values between 6 and 9 (exlusive of 10)\n",
    "t8_randint=torch.randint(6,10,(5,)) # upper bound exclusive\n",
    "print(t8_randint)\n",
    "print(t8_randint.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 9, 9],\n",
      "        [9, 6, 8],\n",
      "        [7, 6, 9]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "#Create a 2-D array (or matrix) of size 3x3 filled with random integers from values between 6 and 9 (exlusive of 10)\n",
    "t9_randint=torch.randint(6,10,(3,3)) # upper bound exclusive\n",
    "print(t9_randint)\n",
    "print(t9_randint.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#Get the number of elemetns in in_array\n",
    "print(torch.numel(t8_randint))\n",
    "#Get the number of elemetns in in_array2\n",
    "print(torch.numel(t9_randint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "torch.Size([3, 3])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "#Construct a 3x3 matrix of zeros and of dtype long:\n",
    "t10_zeros = torch.zeros((3,3),dtype=torch.long)\n",
    "print(t10_zeros)\n",
    "print(t10_zeros.shape)\n",
    "#Construct a 3x3 matrix of ones\n",
    "t11_ones = torch.ones((3,3))\n",
    "print(t11_ones)\n",
    "print(t11_ones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6253,  0.5343, -1.0776],\n",
      "        [ 0.0133,  1.5922, -0.3261]], dtype=torch.float64)\n",
      "torch.Size([2, 3])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#create a tensor of another tensor's shape but different datatype\n",
    "t12_double = torch.randn_like(t3_float,dtype=torch.double)\n",
    "print(t12_double)\n",
    "print(t12_double.shape)\n",
    "print(t3_float)\n",
    "print(t3_float.shape)\n",
    "#while creating int type tensor from float type encountered error\n",
    "# RuntimeError: _th_normal_ not supported on CPUType for Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6253, 2.5343, 1.9224],\n",
      "        [4.0133, 6.5922, 5.6739]], dtype=torch.float64)\n",
      "torch.float64\n",
      "tensor([[1.6253, 2.5343, 1.9224],\n",
      "        [4.0133, 6.5922, 5.6739]], dtype=torch.float64)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "#Add two tensors, make sure they are the same size and data type\n",
    "t13_add = t3_float + t12_double\n",
    "print(t13_add)\n",
    "print(t13_add.dtype)\n",
    "t13_add = torch.add(t3_float,t12_double)\n",
    "print(t13_add)\n",
    "print(t13_add.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6253, 2.5343, 1.9224],\n",
      "        [4.0133, 6.5922, 5.6739]], dtype=torch.float64)\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#inplace addition\n",
    "t12_double.add_(t3_float)\n",
    "print(t12_double)\n",
    "print(t12_double.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([4.0133, 6.5922], dtype=torch.float64)\n",
      "tensor([4.0133, 6.5922], dtype=torch.float64)\n",
      "tensor([1.9224, 5.6739], dtype=torch.float64)\n",
      "tensor([1.9224, 5.6739], dtype=torch.float64)\n",
      "6.592206301363558\n"
     ]
    }
   ],
   "source": [
    "#selecting data from tensor/ slicing an array\n",
    "print(t12_double.shape)\n",
    "#print first row and first 2 colunms \n",
    "print(t12_double[1,:2]) #forward indexing\n",
    "print(t12_double[1,-3:-1]) # reverse indexing\n",
    "#print all rows  and last columns\n",
    "print(t12_double[:,-1])\n",
    "print(t12_double[:,2])\n",
    "#printing the item in the tensor\n",
    "#print the 5th element of the tensor\n",
    "print(t12_double[1,1].item()) # remeber in tensor index starts with 0 not 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy package \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "[[3. 3. 3. 3.]\n",
      " [3. 3. 3. 3.]\n",
      " [3. 3. 3. 3.]]\n",
      "tensor([[5., 5., 5., 5.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [5., 5., 5., 5.]])\n",
      "[[3. 3. 3. 3.]\n",
      " [3. 3. 3. 3.]\n",
      " [3. 3. 3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# converting one torch tensor into numpy array\n",
    "t14_torch = torch.ones(3,4)\n",
    "arr1_np = t14_torch.numpy()\n",
    "print(type(t14_torch))\n",
    "print(type(arr1_np))\n",
    "# impact of the inplace operation\n",
    "t14_torch.add_(2)\n",
    "print((t14_torch))\n",
    "print((arr1_np))\n",
    "#impact of normal addition \n",
    "t14_torch = t14_torch + 2\n",
    "print((t14_torch))\n",
    "print((arr1_np))\n",
    "# since the inplace addition is impacting both we need to use it carefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], dtype=torch.float64)\n",
      "[[2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]]\n",
      "tensor([[2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.]], dtype=torch.float64)\n",
      "[[3. 3. 3. 3. 3.]\n",
      " [3. 3. 3. 3. 3.]\n",
      " [3. 3. 3. 3. 3.]\n",
      " [3. 3. 3. 3. 3.]\n",
      " [3. 3. 3. 3. 3.]]\n",
      "tensor([[2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#Converting NumPy Array to Torch Tensor\n",
    "#See how changing the np array changed the Torch Tensor automatically\n",
    "a=np.ones([5,5])\n",
    "print(a)\n",
    "b=torch.from_numpy(a)\n",
    "print(b)\n",
    "np.add(a,1,out=a)\n",
    "print(a)\n",
    "print(b)\n",
    "a=a+1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5]\n",
      "tensor([2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "#You can also convert a list to a tensor\n",
    "a=[2,3,4,5]\n",
    "print(a)\n",
    "to_list=torch.tensor(a)\n",
    "print(to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "#convert tuple into a tensor\n",
    "data=([2,3],[3,4],[4,5])\n",
    "print(type(data))\n",
    "to_tensor=torch.tensor(data)\n",
    "print(to_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor concatenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "# concat along dim = 0 or rows \n",
    "t15_concat = torch.randn(3,5)\n",
    "t16_concat = torch.randn(2,5)\n",
    "t17_concat = torch.cat([t15_concat,t16_concat],axis = 0)\n",
    "print('\\n concatenating along 0 dim or rows')\n",
    "print(t17_concat.shape)\n",
    "# concat along dim = 1 or cols\n",
    "t18_concat = torch.randn(2,2)\n",
    "t19_concat = torch.randn(2,3)\n",
    "t20_concat = torch.cat([t18_concat,t19_concat],axis = 1)\n",
    "print('\\n concatenating along 1 dim or cols')\n",
    "print(t20_concat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding dimensions to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([4])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "#adding dimension of 1 along a specified index\n",
    "tensor_1 = torch.tensor([1, 2, 3, 4])\n",
    "tensor_a = torch.unsqueeze(tensor_1, 0)\n",
    "print(tensor_a)\n",
    "print(tensor_a.shape)\n",
    "print(tensor_1.shape)\n",
    "tensor_b = torch.unsqueeze(tensor_1,1)\n",
    "print(tensor_b)\n",
    "print(tensor_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7112, 0.5636, 0.3821, 0.0331],\n",
      "         [0.6510, 0.9916, 0.5151, 0.8145],\n",
      "         [0.1329, 0.7640, 0.7334, 0.0437]],\n",
      "\n",
      "        [[0.4863, 0.8903, 0.9182, 0.6826],\n",
      "         [0.8329, 0.4130, 0.3873, 0.0187],\n",
      "         [0.3849, 0.4522, 0.1472, 0.9908]]])\n",
      "tensor([[0.3821, 0.5151, 0.7334],\n",
      "        [0.9182, 0.3873, 0.1472]])\n",
      "torch.Size([2, 3])\n",
      "\n",
      "\n",
      "tensor([[[0.3821],\n",
      "         [0.5151],\n",
      "         [0.7334]],\n",
      "\n",
      "        [[0.9182],\n",
      "         [0.3873],\n",
      "         [0.1472]]])\n",
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor_2 = torch.rand(2,3,4)\n",
    "print(tensor_2)\n",
    "tensor_c = tensor_2[:,:,2] # selecting column 3 for both channels\n",
    "print(tensor_c)\n",
    "print(tensor_c.shape)\n",
    "print('\\n')\n",
    "tensor_d = torch.unsqueeze(tensor_c,2)\n",
    "print(tensor_d)\n",
    "print(tensor_d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.,  9., 11.],\n",
      "        [12., 14., 16.]], grad_fn=<AddBackward0>)\n",
      "tensor(6.0000, grad_fn=<SumBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[3.3379e-06, 1.1921e-07, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([[3.3379e-06, 1.1921e-07, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "#if we want to calculate the derivative w.r.t one element we need to select requires_grad = True\n",
    "# by default the requires_grad = False\n",
    "# important : if you select this for tensor of type int then will throw below error\\\n",
    "# RuntimeError: Only Tensors of floating point dtype can require gradients\n",
    "#example\n",
    "x = torch.tensor([[1.,2,3],[3,4,5]],requires_grad=True)\n",
    "y = torch.tensor([[6,7.,8],[9,10,11]],requires_grad=True)\n",
    "z = x+y\n",
    "a = torch.sum(torch.tanh(z))\n",
    "print(z)\n",
    "print(a)\n",
    "a.backward()\n",
    "print(a.grad)\n",
    "print(z.grad)\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "\n",
    "# # we can calculate gradient of scaler only\n",
    "# that means the final o/p should be a scaler quantity\n",
    "# also the grad will not calculate values for intermediate variables\n",
    "# like here if you see the a.grad and z.grad it will show None\n",
    "# It will only show values for x.grad and y.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "None\n",
      "<AddBackward0 object at 0x000001F407766D08>\n",
      "True\n",
      "None\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# By default, Tensors have `requires_grad=False`\n",
    "x = torch.randn(2, 2)\n",
    "y = torch.randn(2, 2)\n",
    "print(x.requires_grad, y.requires_grad)\n",
    "z = x + y\n",
    "# So you can't backprop through z\n",
    "print(z.grad_fn)\n",
    "#Another way to set the requires_grad = True is\n",
    "x.requires_grad_()\n",
    "y.requires_grad_()\n",
    "# z contains enough information to compute gradients, as we saw above\n",
    "z = x + y\n",
    "print(z.grad_fn)\n",
    "# If any input to an operation has ``requires_grad=True``, so will the output\n",
    "print(z.requires_grad)\n",
    "# Now z has the computation history that relates itself to x and y\n",
    "\n",
    "new_z = z.detach()\n",
    "print(new_z.grad_fn)\n",
    "# z.detach() returns a tensor that shares the same storage as ``z``, but with the computation history forgotten. \n",
    "#It doesn't know anything about how it was computed.In other words, we have broken the Tensor away from its past history\n",
    "\n",
    "#You can also stop autograd from tracking history on Tensors. This concept is useful when applying Transfer Learning \n",
    "print(x.requires_grad)\n",
    "print((x+10).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x+10).requires_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
